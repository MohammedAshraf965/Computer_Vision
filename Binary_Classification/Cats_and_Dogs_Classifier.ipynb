{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a46b5737-0a25-44e8-bfd9-dc3980438e66",
   "metadata": {},
   "source": [
    "# Binary Classification Model for Cat and Dog Classification\n",
    "\n",
    "This is a binary classification model for the famous cat and dog classification problem in Kaggle. Different methods are used to improve the validation accuracy and avoid overfitting.Though the dataset is around 3000 images, it provides the necessary steps for a much larger, complex CNN. Tensorflow library will be used for preprocessing, training and validating the CNN. Different methods that will be applied are:\n",
    "\n",
    "- **Data Augmentation**\n",
    "- **Dropout Layers**\n",
    "- **Transfer Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b877822-23c7-4124-99d5-375ac2ea0f93",
   "metadata": {},
   "source": [
    "Import the libraries to be used. I have downloaded and unzipped the dataset to the local machine. You can download the dataset and\n",
    "use the zip functions to unzip and then use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d04ce-b9b1-4e84-836c-8dbae7108168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52190cf5-7380-4209-acce-f778bae364b9",
   "metadata": {},
   "source": [
    "Copy the directory path to the base_dir and view the subdirectories for the training and validating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5214c845-1f1c-4ea2-99b5-14da43f5dace",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'cats_and_dogs_filtered'\n",
    "\n",
    "print('Contents of base directory')\n",
    "print(os.listdir(base_dir))\n",
    "\n",
    "print('Contents of train directory')\n",
    "print(os.listdir(f'{base_dir}/train'))\n",
    "\n",
    "print('Contents of validation directory')\n",
    "print(os.listdir(f'{base_dir}/validation'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3512307-e299-4794-81f0-dad371aba3c6",
   "metadata": {},
   "source": [
    "Seperate the paths for the training and validating datasets for both classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e4f80-4583-4075-95c7-3a4810b466da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0f7670-b950-4deb-933e-6a5d88bd883b",
   "metadata": {},
   "source": [
    "You can view the total size of the dataset and view samples of the images for both classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c6178-d3ab-4049-9797-6184e7d388ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat_fnames = os.listdir(train_cats_dir)\n",
    "train_dog_fnames = os.listdir(train_dogs_dir)\n",
    "\n",
    "print('Total train cat images: ', len(os.listdir(train_cats_dir)))\n",
    "print('Total train dog images: ', len(os.listdir(train_dogs_dir)))\n",
    "\n",
    "print('Total validation cat images: ', len(os.listdir(validation_cats_dir)))\n",
    "print('Total validation dog images: ', len(os.listdir(validation_dogs_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278bfe9a-1c5c-4214-8a13-e966fea97a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "img_index = 0\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols*4, nrows*4)\n",
    "\n",
    "img_index+=8\n",
    "\n",
    "next_cat_img = [os.path.join(train_cats_dir,fname) for fname in train_cat_fnames[img_index-8:img_index]]\n",
    "\n",
    "next_dog_img = [os.path.join(train_dogs_dir,fname) for fname in train_dog_fnames[img_index-8:img_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_cat_img+next_dog_img):\n",
    "    \n",
    "    sp = plt.subplot(nrows, ncols, i+1)\n",
    "    sp.axis('Off')\n",
    "\n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64908557-dc47-4d91-9ded-f44f6d3b4264",
   "metadata": {},
   "source": [
    "Create the function that creates the sequential model for the CNN\n",
    "\n",
    "- **Relu** is used for the upper layers while sigmoid works best for the output layer of binary problems\n",
    "- Size of the image is defined for the **input_shape** parameter\n",
    "- Features, window sizes, and the number of layers are specified. It can be changed according to the project's specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885870cb-3314-4363-bfa7-c0aa7f23a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150,150,3)),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09373dbf-403b-4b8d-939a-a98959677033",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a93518-399c-4f2e-9238-618cd8b9040d",
   "metadata": {},
   "source": [
    "Specify and compile the model for the optimizer, loss function, and the evaluation metrics according to the project. **Binary\n",
    "crossentropy** works best for binary problems. The evaluation metrics will be the **accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3074491-dcb6-48a6-b371-a56cf8de5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb412729-f5c7-4ec8-a120-407387fb9b20",
   "metadata": {},
   "source": [
    "The **ImageDataGenerator** will be used to preprocess the dataset to be fed to the CNN. Normalized data works better for NN since it\n",
    "eases the calculations. The range is usually [0,1] for the 8-bit images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fd158d-bc4e-4e4a-82d0-45e126ec657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150,150))\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
    "                                                        batch_size=20,\n",
    "                                                        class_mode='binary',\n",
    "                                                        target_size=(150,150))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1730ff89-2b8a-41b1-90ce-4fd62b6105b9",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Train the model on the datasets preprocessed by the ImageDataGenerator. The number of epochs is specified and can be tuned as needed. The results are stored for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad7295-259e-4f87-b87d-36b3294974d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_generator,\n",
    "                    verbose=2\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf4b193-b7ac-4ce8-962e-ab32a20da15e",
   "metadata": {},
   "source": [
    "Visualization of the model's results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406a2575-cc4c-4f83-af32-4bc2e61c0a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_loss(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].plot(epochs, acc, 'bo', label='Training_Accuracy')\n",
    "    ax[0].plot(epochs, val_acc, 'b', label='Validation_Accuracy')\n",
    "    ax[0].set_title('Training and Validation Accuracy')\n",
    "    ax[0].set_xlabel('epochs')\n",
    "    ax[0].set_ylabel('accuracy')\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(epochs, loss, 'bo', label='Training_Loss')\n",
    "    ax[1].plot(epochs, val_loss, 'b', label='Validation_Loss')\n",
    "    ax[1].set_title('Training and Validation Loss')\n",
    "    ax[1].set_xlabel('epochs')\n",
    "    ax[1].set_ylabel('loss')\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e9e294-a08e-45a7-a97a-938067a1de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc75b68c-e3e9-4181-ba82-528bfc8eb9f8",
   "metadata": {},
   "source": [
    "## **Data Augmentation**\n",
    "\n",
    "**Data Augmentation** is used to introduce more features to the dataset that helps the model reduce overfitting. Data augmentation is not the reason to overcome overfitting, it is the diversity in the inputs. The variation in the validating curve is that the validation dataset is too sparse and the dataset may be poorly designed. This means that the data augmentation introduces randomness in the training but if the validation dataset lacks this, then this will result in the curve fluctuationing.\n",
    "**Overcome: Broad set of images in both the training and validation datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051debfd-ec35-405b-af7d-6413666ec0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(150,150),\n",
    "    batch_size=20,\n",
    "    label_mode='binary')\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    image_size=(150,150),\n",
    "    batch_size=20,\n",
    "    label_mode='binary')\n",
    "\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "PREFETCH_BUFFER_SIZE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset_final = (train_dataset\n",
    "                       .cache()\n",
    "                       .shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "                       .prefetch(buffer_size=PREFETCH_BUFFER_SIZE))\n",
    "\n",
    "validation_dataset_final = (validation_dataset\n",
    "                       .cache()\n",
    "                       .shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "                       .prefetch(buffer_size=PREFETCH_BUFFER_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefdf723-375b-4e4b-9b91-2e203db175ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(150,150,3)),\n",
    "    tf.keras.layers.RandomFlip('horizontal'),\n",
    "    # The amount mentioned is a fraction of pi that limits the rotation of the images\n",
    "    # nearest argument tells the model how to fill any pixels that might have been lost by the operations (fill_mode='nearest')\n",
    "    tf.keras.layers.RandomRotation(0.4),\n",
    "    # Center of the image is translated by a fraction horizontally and vertically\n",
    "    tf.keras.layers.RandomTranslation(0.2, 0.2),\n",
    "    # Modify the contrast of the images\n",
    "    tf.keras.layers.RandomContrast(0.4),\n",
    "    # Random zooming through a ceratin factor\n",
    "    tf.keras.layers.RandomZoom(0.2)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32831f85-85bf-4f9e-b8af-36b3bb4556d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_aug = create_model()\n",
    "\n",
    "EPOCHS = 15\n",
    "\n",
    "# Joining the original dataset without augmentation and the augmentation sequence model\n",
    "model_with_aug = tf.keras.models.Sequential([\n",
    "    data_augmentation,\n",
    "    model_without_aug\n",
    "])\n",
    "\n",
    "model_with_aug.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model_with_aug.fit(\n",
    "    train_dataset_final,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_dataset_final,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441be905-f425-48bf-a7ec-94ee854d4520",
   "metadata": {},
   "source": [
    "## **Transfer Learning**\n",
    "\n",
    "As the data was small (3000 images is still insufficient), features trained in another model will be used instead as a fast and \n",
    "an efficent method to train our model, this is done using **transfer learning**. This methods works by utilizing the weights from \n",
    "another model that has been trained for an extensive amount of time and data and instead of retraining them on our data, the other model will extract the features from our data using the **convolutions** that they already learned. Then, you can take the model and use the convolutions that it learned when classifying its data. Then retrain the dense layers with your data\n",
    "\n",
    "The model used is the inception model. It is already supported by Keras but the weights can be obtained from the following link:\n",
    "https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de023ca7-0368-43f5-a953-58ac7a33206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_weights = 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "pre_trained_model = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    input_shape = (150,150,3),\n",
    "    # The model has a fully connected layer at the top. False is used to specify that you want to ignore this and get straight to\n",
    "    # the convolutions\n",
    "    include_top = False,\n",
    "    weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(inception_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0255ff9-60bf-4221-be61-3d5ab6179a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The instantiated model will have its layers locked to not be trained\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5160e358-7808-4def-9c69-f72ae293ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19474b5b-ea77-4744-835d-c2d66850978d",
   "metadata": {},
   "source": [
    "Layers can be accessed using the function **get_layer()**. This helps determine which layer is suitable for the project as the model\n",
    "can be copied and utilized for the desired project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8263fd89-acea-4f63-a74c-f93d221fb832",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a0b585-5b8e-4dce-a7a7-272482cff0e5",
   "metadata": {},
   "source": [
    "## Dropout Layers\n",
    "\n",
    "Layers in a NN can sometimes end up having **similar** weights and possibly impact eachother leading to overfitting. For neighbours\n",
    "to not affect each other too much and potentially remove overfitting, **dropout layers** are used. When validation is diverging away from the training overtime, an overcome is to try to use a dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4225e-035b-49cc-806c-f3cd50a610ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new model taking the output from the inception models mix seven layer\n",
    "\n",
    "x = tf.keras.layers.Flatten()(last_output)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(pre_trained_model.input,x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d6f5c-0d7c-460b-bb17-b365f58dcdfd",
   "metadata": {},
   "source": [
    "Since each model has its requirements for the inputs, the inception model requires the input to be processed in a certain way to\n",
    "work correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230db3fc-c848-430c-8df9-24b42df50e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is required to preprocess the data according to what is mentioned in the documentation of the used model. This model requires\n",
    "# the input to be scaled in the range [-1, 1] with its function preprocess_input()\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tf.keras.applications.inception_v3.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "trained_dataset_scaled = train_dataset.map(preprocess)\n",
    "validation_dataset_scaled = validation_dataset.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5b5c9-8e29-4900-8c75-390fc25e104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_final = (trained_dataset_scaled\n",
    "                       .cache()\n",
    "                       .shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "                       .prefetch(buffer_size=PREFETCH_BUFFER_SIZE))\n",
    "\n",
    "validation_dataset_final = (validation_dataset_scaled\n",
    "                       .cache()\n",
    "                       .prefetch(buffer_size=PREFETCH_BUFFER_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e85d88-0c57-4d47-a4fa-1c53a125bbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(150, 150, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = model(x)\n",
    "\n",
    "# The input and the augmented models are joined\n",
    "final_model = tf.keras.Model(inputs, x)\n",
    "\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9d3af0-2f18-4ce3-9932-60a9fe8b0a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a58c44-5a71-4136-bb18-e620fe7f8f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "\n",
    "history = final_model.fit(\n",
    "    train_dataset_final,\n",
    "    validation_data=validation_dataset_final,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7a8a2f-52e2-4cbc-8723-1ad43646e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a298e70-5157-4610-99a3-4b8a4538a3b9",
   "metadata": {},
   "source": [
    "The sync between Training and Validation result is a sign that overfitting is being avoided. Thus, leading to a more accurate model\n",
    "for binary classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0769ac-6f53-4a77-bd9c-6b004d20cd48",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "The model initially created had the training and validation accuracy greatly varying, which led to overfitting. Several methods were applied to help reduce overfitting and to provide a good classifier. However, without transfer learning, the model needs a very large dataset and a large amount of epochs to provide accurate results for large scale projects"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
